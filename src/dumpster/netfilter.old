"""
Dumpster reads netfilter logs, parses them, and then acts on them.

"""

__version__ = "0.0.3"

import tomllib
from asyncio import sleep
from os.path import exists, isfile
from queue import Queue
from re import search
from signal import SIGUSR1, signal

from zenlib.logging import loggify
from zenlib.types import validatedDataclass

from protocol_parser import ProtocolParser
from service_parser import ServiceParser

NF_FLAGS = {
    "ACK": "TCP Acknowledgement",
    "FIN": "TCP Finish",
    "SYN": "TCP Synchronize",
    "RST": "TCP Reset",
    "PSH": "TCP Push",
    "URG": "TCP Urgent",
    "ECE": "TCP ECN-Echo",
    "ECT": "TCP ECN-Capable Transport",
    "CWR": "TCP Congestion Window Reduced",
    "CE": "TCP Congestion Experienced",
    "DF": "Don't fragment",
}


def make_netfilter_base():
    """Creates a base class for Netfilter flags"""
    class NetFilterFlagMixin:
        """ Mixin with attributes for Netfilter flags """
        pass
    for flag in NF_FLAGS:
        setattr(NetFilterFlagMixin, flag, False)

    NetFilterFlagMixin.__annotations__ = {flag: bool for flag in NF_FLAGS}
    return NetFilterFlagMixin

NetFilterFlagMixin = make_netfilter_base()

def get_flags(raw_line):
    for flag in NF_FLAGS:
        flag_re = r"\s%s[\s|$]" % flag
        if search(flag_re, raw_line):
            yield flag

def split_mac(mac):
    """Splits the mac address into the SRC and DST MAC addresses"""
    mac_re = r"([a-fA-F0-9]{2}(?:\:[a-fA-F0-9]{2}){5})"
    mac_match = search(mac_re, mac)
    src_mac = mac_match.group(0)
    dst_mac = mac_match.group(1)
    return src_mac, dst_mac


class MacAddress:
    @staticmethod
    def from_logline(mac_section):
        return map(MacAddress, split_mac(mac_section))

    def __init__(self, mac):
        self.mac = mac

    @property
    def mac(self):
        return str(self)

    @mac.setter
    def iset_mac(self, mac):
        self._mac = mac

    def __str__(self):
        return str(self.mac)


@validatedDataclass
class NetFilterLogLine(NetFilterFlagMixin):
    """Parses a Netfilter log line"""

    NF_Parameters = {
        "IN": "Input interface",
        "OUT": "Output interface",
        "MAC": "MAC addresses",
        "SRC": "Source IP address",
        "DST": "Destination IP address",
        "L3_LEN": "Length of packet",
        "TOS": "Type of service",
        "PREC": "Precedence",
        "TTL": "Time to live",
        "ID": "Identification",
        "PROTO": "Protocol",
        "SPT": "Source port",
        "DPT": "Destination port",
        "L4_LEN": "Length of layer 4 portion",
    }

    _MAC_special = {"multicast": "01:00:5e"}

    def __init__(self, line, protocols=None, services=None, aliases=None, *args, **kwargs):
        if not protocols:
            protocols = ProtocolParser(logger=self.logger).protocols
        self.protocols = protocols
        if not services:
            services = ProtocolParser(logger=self.logger).services
        self.services = services

        self.raw_line = line.strip()
        self.aliases = aliases
        self.log_type = "forward"  # Default to forward
        self.parse_line()

    def parse_line(self):
        """Parses the raw line"""
        self.logger.debug("Parsing line: %s" % self.raw_line)
        # Start by splitting the line using the "IN=" portion
        if " IN=" not in self.raw_line:
            raise ValueError("Unable to process line as a netfilter line, missing 'IN=': %s" % self.raw_line)

        pre_in = self.raw_line.split("IN=")[0]
        self._parse_pre_in(pre_in)

        for flag in get_flags(self.raw_line):
            setattr(self, flag, True)

        # Parse the packet based on the parameters
        for param in self.NF_Parameters.keys():
            # Don't parse length here
            if "_LEN" in param:
                continue
            # Search for the parameter by looking for " {param}={value} "
            re_pattern = r" %s=([\S]+)\s?" % param
            match = re.search(re_pattern, self.raw_line)
            if match:
                if param == "MAC":
                    self._parse_mac(match.group(1))
                if param == "PROTO":
                    # Check if the protocol is a number
                    if match.group(1).isdigit():
                        self.PROTO = self.protocols[match.group(1)]
                    else:
                        self.PROTO = match.group(1)
                else:
                    setattr(self, param, match.group(1))
            else:
                if param == "IN":
                    self.logger.debug("Input parameter not found, setting type to 'outbound'")
                    self.log_type = "outbound"
                elif param == "OUT":
                    self.logger.debug("Output parameter not found, setting type to 'inbound'")
                    self.log_type = "inbound"
                elif param in ("SPT", "DPT"):
                    if self.PROTO in ("TCP", "UDP"):
                        raise ValueError("Port is unset when it should be set: %s" % self.raw_line)
                    else:
                        self.logger.debug("Port is missing but protocol is not TCP or UDP, setting to '0'")
                        setattr(self, param, "0")
                else:
                    self.logger.warning("Unable to find parameter: %s" % param)
                    setattr(self, param, None)

    def _parse_pre_in(self, pre_in):
        """Parses the pre-IN portion of the line"""
        self.logger.debug("Parsing pre-IN portion: %s" % pre_in)

        # Split the pre-in portion around the 'kernel:' portion
        front, back = pre_in.split(" kernel: ")
        self.log_statement = back.strip()

        # The hostname should be the last portion of the front
        hostname = front.split(" ")[-1]
        self.hostname = hostname.strip()

        # Get the timestamp by removing the hostname from the front
        self.timestamp = front.replace(hostname, "").strip()

    def _display_mac(self, mac):
        """
        Formats a MAC address to be diplayed.
        Special mac types such as multicast take precedence over aliases.
        """
        # If the MAC is a multicast, then return the special string
        for name, prefix in self._MAC_special.items():
            if mac.startswith(prefix):
                return f"{name}{mac.replace(prefix,'').replace(':00', '')}"

        if mac in self.aliases.get("mac_name").keys():
            return f"@{self.aliases.get('mac_name').get(mac)}"

        return mac

    def _display_ip(self, ip):
        """
        Formats an IP address to be displayed.
        If an alias exists, displays that alias with a @ in front of it.
        """
        if ip in self.aliases.get("ip_name").keys():
            return f"@{self.aliases.get('ip_name').get(ip)}"

        return ip

    def display_src_ip(self):
        """Returns a string representation of the source IP"""
        return self._display_ip(self.SRC)

    def display_dst_ip(self):
        """Returns a string representation of the destination IP"""
        return self._display_ip(self.DST)

    def display_src_mac(self):
        """Returns a string representation of the source MAC"""
        return self._display_mac(self.SRC_MAC)

    def display_dst_mac(self):
        """Returns a string representation of the destination MAC"""
        return self._display_mac(self.DST_MAC)

    def display_src_port(self):
        """Returns a string representation of the source port"""
        return self._display_port(self.SPT, self.PROTO)

    def display_dst_port(self):
        """Returns a string representation of the destination port"""
        return self._display_port(self.DPT, self.PROTO)

    def _display_port(self, port, proto):
        """
        Formats a port to be displayed.
        If a service defintion exists, displays that service with a @ in front of it.
        """
        proto = proto.lower()
        if proto in self.services and port in self.services[proto]:
            return f"@{self.services[proto][port]}"
        return port

    def __str__(self):
        """Returns a string representation of the object"""
        log_type = f"<{self.log_type}>".ljust(10, " ")
        src_mac_alias = self._display_mac(self.SRC_MAC)
        src_ip_alias = self._display_ip(self.SRC)
        src_port_alias = self._display_port(self.SPT, self.PROTO)
        src_str = f"({src_mac_alias}) {src_ip_alias}:{src_port_alias} ".ljust(46, " ")

        proto_str = f"-{self.PROTO}->".ljust(8, " ")

        dst_mac_alias = self._display_mac(self.DST_MAC)
        dst_ip_alias = self._display_ip(self.DST)
        dst_port_alias = self._display_port(self.DPT, self.PROTO)
        dst_str = f"({dst_mac_alias}) {dst_ip_alias}:{dst_port_alias} ".ljust(46, " ")

        flags = ""

        for flag in self.NF_Flags.keys():
            if getattr(self, flag):
                flags += f"{self.NF_Flags[flag]}, "
        flags = flags.rstrip(" ,")

        return f"[{self.timestamp}] {log_type} {self.hostname}: {src_str} {proto_str} {dst_str} <{flags}>"


@loggify
class NetfilterLogReader:
    """Reads Netfilter logs, parses into a Queue"""

    def __init__(self, config_file="config.toml", *args, **kwargs):
        signal(SIGUSR1, self._reload_files)
        self.config_file = config_file
        self.read_config()
        # Get the protocol config from the protocol file
        self.protocols = ProtocolParser(self.config["source_files"].get("protocol_file"), logger=self.logger).protocols
        # Get the service config from the service file
        self.services = ServiceParser(self.config["source_files"].get("service_file"), logger=self.logger).services

        self.log_items = Queue()

    def run(self):
        from asyncio import get_event_loop

        get_event_loop().run_until_complete(self.watch_logs())

    def read_config(self):
        """Reads the config file."""
        self.logger.info("Reading config file: %s" % self.config_file)
        with open(self.config_file, "rb") as f:
            self.config = tomllib.load(f)
        self.log_files = self.config["log_files"]

    def watch_logs(self):
        """Watches the log files"""
        from asyncio import create_task

        [create_task(self.watch_log(log_file)) for log_file in self.log_files.values()]

    async def watch_log(self, log_file):
        """Reads the log file, parses it, and puts it in the queue"""
        if not exists(log_file) or not isfile(log_file):
            raise FileNotFoundError("Log file does not exist: %s" % log_file)

        with open(log_file, "r") as f:
            self.logger.info("Watching log file: %s" % f.name)
            while True:
                if line := f.readline():
                    try:
                        log_item = NetFilterLogLine(
                            line,
                            protocols=self.protocols,
                            services=self.services,
                            aliases=self.config["aliases"],
                            logger=self.logger,
                            _log_init=False,
                        )
                        self.log_items.put(log_item)
                        self.logger.debug("Added log line to queue: %s" % log_item)
                    except ValueError as e:
                        self.logger.error(e)
                else:
                    await sleep(0.1)
        self.logger.info("Closed log file: %s" % log_file)

    def _reload_files(self, *args, **kwargs):
        """Reloads watched log files"""
        self.logger.info("Detected reload signal, reloading config file")
